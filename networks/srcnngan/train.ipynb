{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "source = None\n",
    "for root, dirs, files in os.walk(r'/content/drive'):\n",
    "    for name in dirs:\n",
    "        if name == 'srcnn':\n",
    "            source = f\"{os.path.abspath(os.path.join(root, name))}{os.sep}implementation.zip\"\n",
    "\n",
    "if source is None: \n",
    "  raise FileNotFoundError(\"Make sure you add a shortcut to Text2Mesh in your drive\")\n",
    "!cp \"{source}\" \"/content/implementation.zip\"\n",
    "\n",
    "!unzip /content/implementation.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from implementation.test import *\n",
    "from implementation.train import *\n",
    "from matplotlib import pyplot as plt\n",
    "from implementation.srcnn import SRCNN\n",
    "from implementation.data_utils import create_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "home_dir = \"/content/implementation\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Computation device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_path = create_dataset(f\"{home_dir}/inputs/vid1.mp4\", home_dir, video=True, max_iters=500)\n",
    "with h5py.File(hf_path) as file:\n",
    "    data_inputs = file['data'][:].astype('float32')\n",
    "    data_labels = file['label'][:].astype('float32') \n",
    "    file.close()\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(data_inputs, data_labels, test_size=0.25)\n",
    "print(f\"Training samples count:\\t{train_inputs.shape[0]}\")\n",
    "print(f\"Validation samples count:\\t{val_inputs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 \n",
    "epochs = 1000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_validate(device, val_inputs, val_labels, train_inputs, train_labels, batch_size, epochs, lr, home_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
